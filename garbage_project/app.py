import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image, ImageOps

# 1. è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="åƒåœ¾åˆ†é¡è­˜åˆ¥ç³»çµ±",
    page_icon="â™»ï¸",
    layout="centered"
)

# 2. æ¨™é¡Œèˆ‡èªªæ˜
st.title("â™»ï¸ æ·±åº¦å­¸ç¿’åƒåœ¾åˆ†é¡ Demo")
st.markdown("""
é€™æ˜¯ä¸€å€‹ä½¿ç”¨ **MobileNetV2** èˆ‡ **Transfer Learning** è¨“ç·´çš„å½±åƒè¾¨è­˜ç³»çµ±ã€‚
è«‹ä¸Šå‚³ä¸€å¼µåƒåœ¾ç…§ç‰‡ï¼ˆå¦‚ï¼šå¯¶ç‰¹ç“¶ã€ç»ç’ƒç½ã€ç´™ç®±ï¼‰ï¼Œç³»çµ±å°‡æœƒè‡ªå‹•åˆ¤æ–·é¡åˆ¥ã€‚
""")

# 3. è¼‰å…¥æ¨¡å‹ (ä½¿ç”¨å¿«å–ï¼Œé¿å…æ¯æ¬¡æ“ä½œéƒ½é‡æ–°è¼‰å…¥)
@st.cache_resource
def load_model():
    # è«‹ç¢ºä¿ä½ çš„æ¨¡å‹æª”åèˆ‡é€™è£¡ä¸€è‡´ï¼Œå¦‚æœä½ çš„æª”åä¸åŒï¼Œè«‹ä¿®æ”¹é€™è£¡
    model_path = 'models/garbage_model.h5'
    try:
        model = tf.keras.models.load_model(model_path)
        return model
    except Exception as e:
        st.error(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼Œè«‹ç¢ºèª {model_path} æ˜¯å¦å­˜åœ¨ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        return None

with st.spinner('æ­£åœ¨è¼‰å…¥ AI æ¨¡å‹...'):
    model = load_model()

# 4. å®šç¾©é¡åˆ¥åç¨± (é€™æ˜¯ Kaggle Garbage Classification çš„æ¨™æº–é †åº)
# é †åºå¿…é ˆèˆ‡ train.py è¨“ç·´æ™‚çš„ class_indices ä¸€è‡´ (é€šå¸¸æ˜¯æŒ‰å­—æ¯é †åº)
CLASS_NAMES = ['ç´™æ¿ (Cardboard)', 'ç»ç’ƒ (Glass)', 'é‡‘å±¬ (Metal)', 'ç´™å¼µ (Paper)', 'å¡‘è†  (Plastic)', 'ä¸€èˆ¬åƒåœ¾ (Trash)']

# 5. åœ–ç‰‡é è™•ç†å‡½æ•¸
def process_image(image_data):
    """
    å°‡åœ–ç‰‡è™•ç†æˆæ¨¡å‹çœ‹å¾—æ‡‚çš„æ ¼å¼ï¼š
    1. èª¿æ•´å¤§å°è‡³ (224, 224)
    2. è½‰æ›ç‚ºé™£åˆ—
    3. æ­¸ä¸€åŒ– (é™¤ä»¥ 255ï¼Œå°‡æ•¸å€¼å£“åœ¨ 0~1 ä¹‹é–“ï¼Œå°æ‡‰ train.py çš„ rescale=1./255)
    """
    size = (224, 224)
    # ä½¿ç”¨ LANCZOS æ¼”ç®—æ³•é€²è¡Œé«˜å“è³ªç¸®æ”¾
    image = ImageOps.fit(image_data, size, Image.Resampling.LANCZOS)
    img_array = np.asarray(image)
    
    # æ­¸ä¸€åŒ– (å¿…é ˆèˆ‡ train.py ä¸€è‡´)
    normalized_image_array = img_array.astype(np.float32) / 255.0
    
    # å¢åŠ ä¸€å€‹ç¶­åº¦ (Batch Size)ï¼Œè®Šæˆ (1, 224, 224, 3)
    data = np.expand_dims(normalized_image_array, axis=0)
    return data

# 6. ä½¿ç”¨è€…ä»‹é¢ - æª”æ¡ˆä¸Šå‚³
uploaded_file = st.file_uploader("è«‹é¸æ“‡ä¸€å¼µåœ–ç‰‡...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None and model is not None:
    # é¡¯ç¤ºä¸Šå‚³çš„åœ–ç‰‡
    image = Image.open(uploaded_file)
    st.image(image, caption='æ‚¨ä¸Šå‚³çš„åœ–ç‰‡', use_column_width=True)
    
    # é€²è¡Œé æ¸¬
    st.write("ğŸ” AI æ­£åœ¨åˆ†æä¸­...")
    
    # é è™•ç†åœ–ç‰‡
    data = process_image(image)
    
    # æ¨¡å‹æ¨è«–
    prediction = model.predict(data)
    
    # å–å¾—æœ€é«˜æ©Ÿç‡çš„é¡åˆ¥
    predicted_class_index = np.argmax(prediction)
    predicted_class_name = CLASS_NAMES[predicted_class_index]
    confidence = prediction[0][predicted_class_index]
    
    # é¡¯ç¤ºçµæœ
    st.markdown("---")
    if confidence > 0.6: # ä¿¡å¿ƒåº¦é–€æª»
        st.success(f"è­˜åˆ¥çµæœï¼š**{predicted_class_name}**")
        st.info(f"ä¿¡å¿ƒæŒ‡æ•¸ï¼š**{confidence * 100:.2f}%**")
    else:
        st.warning(f"è­˜åˆ¥çµæœå¯èƒ½æ˜¯ï¼š**{predicted_class_name}** (ä½†æˆ‘ä¸ç¢ºå®š ğŸ¤”)")
        st.caption(f"ä¿¡å¿ƒæŒ‡æ•¸ï¼š{confidence * 100:.2f}%")
        
    # é¡¯ç¤ºè©³ç´°æ©Ÿç‡é•·æ¢åœ–
    st.markdown("### è©³ç´°é æ¸¬æ•¸æ“š")
    st.bar_chart(dict(zip(CLASS_NAMES, prediction[0])))

elif model is None:
    st.warning("âš ï¸ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œç„¡æ³•é€²è¡Œé æ¸¬ï¼Œè«‹æª¢æŸ¥ models è³‡æ–™å¤¾ã€‚")